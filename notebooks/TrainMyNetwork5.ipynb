{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec7a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "printGraph (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract type GraphNode end\n",
    "abstract type Operator <: GraphNode end\n",
    "\n",
    "struct Constant{T} <: GraphNode\n",
    "    output :: T\n",
    "end\n",
    "\n",
    "mutable struct Variable <: GraphNode\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    Variable(output; name=\"?\") = new(output, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct ScalarOperator{F} <: Operator\n",
    "    inputs :: Any\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    ScalarOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "\n",
    "mutable struct BroadcastedOperator{F} <: Operator\n",
    "    inputs :: Any\n",
    "    output :: Any\n",
    "    gradient :: Any\n",
    "    name :: String\n",
    "    BroadcastedOperator(fun, inputs...; name=\"?\") = new{typeof(fun)}(inputs, nothing, nothing, name)\n",
    "end\n",
    "\n",
    "function printGraph(graph)\n",
    "    println(\"\\ngraph ( $(length(graph)) ):\")\n",
    "    for node_idx in 1:length(graph)\n",
    "        print(\"$(node_idx):\")\n",
    "        show(graph[node_idx])\n",
    "#         print(\", output: \", graph[node_idx].output != nothing && length(graph[node_idx].output) > 10 ? \"huge\" : graph[node_idx].output)\n",
    "               \n",
    "#         println(\"typeof(graph[node_idx]):\", typeof(graph[node_idx]))\n",
    "#         if typeof(graph[node_idx]) != Constant && (graph[node_idx].gradient == nothing || length(graph[node_idx].gradient) < 10)\n",
    "#             print(\", gradient: $(graph[node_idx].gradient)\")\n",
    "#         end\n",
    "        \n",
    "        println(\"\")\n",
    "    end\n",
    "    println(\"END OF graph\\n\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5c7784",
   "metadata": {},
   "source": [
    "### Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a42c22c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topological_sort (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function visit(node::GraphNode, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "    \n",
    "function visit(node::Operator, visited, order)\n",
    "    if node ∈ visited\n",
    "    else\n",
    "        push!(visited, node)\n",
    "        for input in node.inputs\n",
    "            visit(input, visited, order)\n",
    "        end\n",
    "        push!(order, node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function topological_sort(head::GraphNode)\n",
    "    visited = Set()\n",
    "    order = Vector()\n",
    "    visit(head, visited, order)\n",
    "    return order\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2f2bd",
   "metadata": {},
   "source": [
    "### Operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "856da0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 8 methods)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: show, summary\n",
    "show(io::IO, x::ScalarOperator{F}) where {F} = begin\n",
    "    print(io, \"op2 \", x.name, \"(\", F, \")\")\n",
    "    print(\", inputs1 ($(length(x.inputs)))\")\n",
    "    println()\n",
    "end\n",
    "show(io::IO, x::BroadcastedOperator{F}) where {F} = begin\n",
    "    print(io)\n",
    "    print(\"op1.\", x.name, \"(\", F, \")\")\n",
    "    print(\", inputs2 ($(length(x.inputs)))\")\n",
    "    print(\", output ($(typeof(x.output))): \", x.output == nothing || length(x.output) <= 10 ? x.output : \"$(x.output[1:2])...\")\n",
    "    print(\", gradient ($(typeof(x.gradient)): \", x.gradient == nothing || length(x.gradient) <= 10 ? x.gradient : \"$(x.gradient[1:2])...\")\n",
    "    println()\n",
    "end\n",
    "show(io::IO, x::Constant) = print(io, \"const \", x.output)\n",
    "show(io::IO, x::Variable) = begin\n",
    "    print(io, \"var \", x.name);\n",
    "    print(io, \"\\n ┣━ ^ \");\n",
    "        summary(io, x.output);\n",
    "        print(\", x.output: \", x.output == nothing || length(x.output) <= 10 ? x.output : \"$(x.output[1:2])...\")\n",
    "    print(io, \"\\n ┗━ ∇ \"); \n",
    "        summary(io, x.gradient)\n",
    "        print(\", x.gradient: \", x.gradient == nothing || length(x.gradient) <= 10 ? x.gradient : \"$(x.gradient[1:2])...\")\n",
    "    println()\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "reset!(node::Constant) = nothing\n",
    "reset!(node::Variable) = node.gradient = nothing\n",
    "reset!(node::Operator) = node.gradient = nothing\n",
    "\n",
    "compute!(node::Constant) = nothing\n",
    "compute!(node::Variable) = nothing\n",
    "compute!(node::Operator) =\n",
    "    node.output = forward(node, [input.output for input in node.inputs]...)\n",
    "\n",
    "function forward!(order::Vector)\n",
    "    for node in order\n",
    "        compute!(node)\n",
    "        reset!(node)\n",
    "    end\n",
    "    return last(order).output\n",
    "end\n",
    "\n",
    "update!(node::Constant, gradient) = nothing\n",
    "update!(node::GraphNode, gradient) =\n",
    "    if isnothing(node.gradient)\n",
    "        node.gradient = gradient\n",
    "    else\n",
    "        node.gradient .+= gradient\n",
    "end\n",
    "\n",
    "function backward!(order::Vector; seed=1.0)\n",
    "    result = last(order)\n",
    "    result.gradient = seed\n",
    "    @assert length(result.output) == 1 \"Gradient is defined only for scalar functions\"\n",
    "    for node in reverse(order)\n",
    "        backward!(node)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function backward!(node::Constant) end\n",
    "function backward!(node::Variable) end\n",
    "function backward!(node::Operator)\n",
    "    inputs = node.inputs\n",
    "    gradients = backward(node, [input.output for input in inputs]..., node.gradient)\n",
    "    for (input, gradient) in zip(inputs, gradients)\n",
    "        update!(input, gradient)\n",
    "    end\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "import Base: ^\n",
    "^(x::GraphNode, n::GraphNode) = ScalarOperator(^, x, n)\n",
    "forward(::ScalarOperator{typeof(^)}, x, n) = return x^n\n",
    "backward(::ScalarOperator{typeof(^)}, x, n, g) = tuple(g * n * x ^ (n-1), g * log(abs(x)) * x ^ n)\n",
    "\n",
    "import Base: *\n",
    "import LinearAlgebra: mul!, diagm\n",
    "# x * y (aka matrix multiplication)\n",
    "*(A::GraphNode, x::GraphNode) = BroadcastedOperator(mul!, A, x)\n",
    "forward(::BroadcastedOperator{typeof(mul!)}, A, x) = return A * x\n",
    "backward(::BroadcastedOperator{typeof(mul!)}, A, x, g) = tuple(g * x', A' * g)\n",
    "\n",
    "# x .* y (element-wise multiplication)\n",
    "Base.Broadcast.broadcasted(*, x::GraphNode, y::GraphNode) = BroadcastedOperator(*, x, y)\n",
    "forward(::BroadcastedOperator{typeof(*)}, x, y) = return x .* y\n",
    "backward(node::BroadcastedOperator{typeof(*)}, x, y, g) = let\n",
    "    𝟏 = ones(length(node.output))\n",
    "    Jx = diagm(y .* 𝟏)\n",
    "    Jy = diagm(x .* 𝟏)\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n",
    "\n",
    "Base.Broadcast.broadcasted(-, x::GraphNode, y::GraphNode) = BroadcastedOperator(-, x, y)\n",
    "forward(::BroadcastedOperator{typeof(-)}, x, y) = return x .- y\n",
    "backward(::BroadcastedOperator{typeof(-)}, x, y, g) = begin\n",
    "    tuple(g,-g)\n",
    "end\n",
    "Base.Broadcast.broadcasted(+, x::GraphNode, y::GraphNode) = BroadcastedOperator(+, x, y)\n",
    "forward(::BroadcastedOperator{typeof(+)}, x, y) = return x .+ y\n",
    "backward(::BroadcastedOperator{typeof(+)}, x, y, g) = begin\n",
    "    return tuple(g, g)\n",
    "end\n",
    "\n",
    "import Base: sum\n",
    "sum(x::GraphNode) = BroadcastedOperator(sum, x)\n",
    "forward(::BroadcastedOperator{typeof(sum)}, x) = return sum(x)\n",
    "backward(::BroadcastedOperator{typeof(sum)}, x, g) = let \n",
    "#     println(\"\\n[SUM]\")\n",
    "    𝟏 = ones(length(x))\n",
    "    J = 𝟏'\n",
    "    tuple(J' * g)\n",
    "end\n",
    "\n",
    "Base.Broadcast.broadcasted(/, x::GraphNode, y::GraphNode) = BroadcastedOperator(/, x, y)\n",
    "forward(::BroadcastedOperator{typeof(/)}, x, y) = return x ./ y\n",
    "backward(node::BroadcastedOperator{typeof(/)}, x, y::Real, g) = let\n",
    "    𝟏 = ones(length(node.output))\n",
    "    @assert 0 ∉ y \"Add some eposilon not to divide by 0 y: $(y)\"\n",
    "    Jx = diagm(𝟏 ./ y)\n",
    "    Jy = (-x ./ y .^2)\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end\n",
    "backward(node::BroadcastedOperator{typeof(/)}, x, y, g) = let\n",
    "    𝟏 = ones(length(node.output))\n",
    "    @assert 0 ∉ y \"Add some eposilon not to divide by 0 y: $(y)\"\n",
    "    Jx = diagm(𝟏 ./ y)\n",
    "    Jy = -x .* diagm(𝟏 ./ (y.^ 2))\n",
    "    tuple(Jx' * g, Jy' * g)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ab53d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backward (generic function with 11 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base:zero, -, exp\n",
    "\n",
    "Base.Broadcast.broadcasted(-, x::GraphNode) = BroadcastedOperator(-, x)\n",
    "-(x::BroadcastedOperator{typeof(-)}) = return BroadcastedOperator(-, x)\n",
    "forward(::BroadcastedOperator{typeof(-)}, x) = return .-x\n",
    "backward(::BroadcastedOperator{typeof(-)}, x, g) = return tuple(-g)\n",
    "\n",
    "\n",
    "Base.Broadcast.broadcasted(exp, x::GraphNode) = BroadcastedOperator(exp, x)\n",
    "exp(x::BroadcastedOperator{typeof(-)}) = return BroadcastedOperator(exp, x)\n",
    "forward(::BroadcastedOperator{typeof(exp)}, x) = begin\n",
    "    return exp.(x)\n",
    "end\n",
    "backward(::BroadcastedOperator{typeof(exp)}, x, g) = return tuple(g .* exp.(x))\n",
    "\n",
    "\n",
    "\n",
    "# dont use this except forward, WHY? \n",
    "Base.Broadcast.broadcasted(^, x::GraphNode) = BroadcastedOperator(^, x)\n",
    "^(x::BroadcastedOperator{typeof(^)}) = return BroadcastedOperator(^, x)\n",
    "forward(::BroadcastedOperator{typeof(^)}, x, n) = return x .^ n\n",
    "backward(::BroadcastedOperator{typeof(^)}, x, n, g) = begin\n",
    "#     println(\"\\n[^]\")\n",
    "    return tuple(g .* n .* x .^ (n.-1), g .* log.(abs.(x)) .* x .^ n)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59f88a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "softmax (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(x) = return Constant(1.0) ./ (Constant(1.0) .+ exp(.-x))\n",
    "softmax(x) = exp.(x) ./ sum(exp.(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6705a943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_weights! (generic function with 2 methods)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets\n",
    "# Init\n",
    "struct Weights\n",
    "    Wh1::Variable\n",
    "    Wh2::Variable\n",
    "    Wo::Variable\n",
    "    Weights() = new(\n",
    "        Variable(randn(32,784), name=\"Wh1\"),\n",
    "        Variable(randn(32,32), name=\"Wh2\"),\n",
    "        Variable(randn(10,32), name=\"Wo\"),\n",
    "    )\n",
    "end\n",
    "\n",
    "onehot_to_digit(y::Vector) = argmax(y) - 1\n",
    "\n",
    "function net(x, weights::Weights)\n",
    "    x1 = sigmoid(weights.Wh1 * x);\n",
    "    x2 = sigmoid(weights.Wh2 * x1);\n",
    "    ŷ = sigmoid(weights.Wo * x2);\n",
    "    return ŷ\n",
    "end\n",
    "\n",
    "function predict_digit(x, weights::Weights)\n",
    "    ŷ = net(x, weights)\n",
    "    o = topological_sort(ŷ)    \n",
    "    forward!(o)\n",
    "    onehot_to_digit(ŷ.output)\n",
    "end\n",
    "\n",
    "function success_percentage(data_set, weights)\n",
    "    return string(\"Percentage of correctly classified images is: \", \n",
    "        sum([ predict_digit(Constant(x[1]), weights) == \n",
    "        argmax(x[2]) - 1 ? 1 : 0 for x in data_set])/length(data_set)*100, \" %\")\n",
    "end\n",
    "\n",
    "function getTestDataset()\n",
    "    test_x, test_y = MNIST.testdata(Float64);\n",
    "    \n",
    "    X = []; \n",
    "    Y = []; \n",
    "\n",
    "    for i = 1 : 10000\n",
    "        push!(X, reshape(test_x[:,:,i],784));\n",
    "        y = zeros(10);\n",
    "        y[test_y[i] + 1] = 1.0; \n",
    "        push!(Y,y);\n",
    "    end\n",
    "\n",
    "    test_data = [x for x in zip(X,Y)]; \n",
    "end\n",
    "\n",
    "function update_weights!(x, weights::Weights, y, lr=0.4)\n",
    "    ŷ = net(x, weights)\n",
    "    E = sum(Constant(0.5).*((y .- ŷ).^Constant(2)));\n",
    "    o = topological_sort(E)\n",
    "    forward!(o)\n",
    "    backward!(o)\n",
    "    weights.Wh1.output -= lr .* weights.Wh1.gradient\n",
    "    weights.Wh2.output -= lr .* weights.Wh2.gradient\n",
    "    weights.Wo.output -= lr .* weights.Wo.gradient\n",
    "    return nothing\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41a99816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Percentage of correctly classified images is: 15.36 %\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicjalizacja wag\n",
    "weights = Weights()\n",
    "test_dataset = getTestDataset()\n",
    "success_percentage(test_dataset, weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "184fa4ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Percentage of correctly classified images is: 34.25 %\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trenowanie zbioru testowego\n",
    "for i=1:1000\n",
    "    x = Constant(test_dataset[i][1])\n",
    "    y = Constant(test_dataset[i][2])\n",
    "    update_weights!(x,weights, y)\n",
    "end\n",
    "success_percentage(test_dataset, weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57af4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pomiary na zbiorze Fisher's iris\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16053c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jan/Dokumenty/Studia/MSem1/Algorytmy_w_inzynierii_danych/sandbox\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "\u001b[91mUndefVarError: MNIST not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: MNIST not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] getTestDataset() at /home/jan/Dokumenty/Studia/MSem1/Algorytmy_w_inzynierii_danych/sandbox/DigitMNIST.jl:3",
      " [2] top-level scope at In[25]:5"
     ]
    }
   ],
   "source": [
    "cd(\"/home/jan/Dokumenty/Studia/MSem1/Algorytmy_w_inzynierii_danych/sandbox\")\n",
    "push!(LOAD_PATH, pwd())\n",
    "println(pwd())\n",
    "import DigitMNIST\n",
    "println(DigitMNIST.getTestDataset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
